{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPgAbrdf6EjYqoOa8Z7PZbX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6chkNaPatbT"},"outputs":[],"source":["# Install TensorFlow and DeepLab\n","!pip install tensorflow==2.6.0\n","!pip install deeplab"]},{"cell_type":"code","source":["# Download Cityscapes dataset\n","!wget --keep-session-cookies --save-cookies=cookies.txt --post-data 'username=YOUR_USERNAME&password=YOUR_PASSWORD' https://www.cityscapes-dataset.com/login/\n","!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=1\n","!unzip leftImg8bit_trainvaltest.zip -d cityscapes"],"metadata":{"id":"JO9cjnnij9rI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python deeplab/datasets/remove_gt_colormap.py --input_folder=cityscapes/gtFine --output_folder=cityscapes/gtFine_labelIds\n","!python deeplab/datasets/create_cityscapes_tfrecord.py --image_folder=cityscapes/leftImg8bit --semantic_segmentation_folder=cityscapes/gtFine_labelIds --list_folder=cityscapes --output_dir=cityscapes/tfrecord\\"],"metadata":{"id":"Ka6w54t0iGTR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model\n","from deeplab import common\n","from deeplab import model\n","from deeplab import input_preprocess\n","\n","config = common.parse_from_config_file('deeplab/configs/cityscapes.yaml')\n","model = model.DeepLabModel(config)\n","\n","train_dataset = input_preprocess.load('cityscapes/tfrecord/train', config, is_training=True)\n","val_dataset = input_preprocess.load('cityscapes/tfrecord/val', config, is_training=False)"],"metadata":{"id":"aB_PgoL1a0ib"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loss function\n","from deeplab import losses\n","from deeplab import utils\n","\n","def compute_loss(model, images, labels):\n","    logits = model(images, training=True)\n","    return losses.cross_entropy(logits, labels, config)\n","\n","from deeplab import lr_schedule\n","from deeplab import optimizer\n","\n","learning_rate_fn = lr_schedule.create_learning_rate_schedule(config)\n","optimizer_fn = optimizer.create_optimizer(config)"],"metadata":{"id":"k4J1BA3DwcXG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training \n","from deeplab import training\n","\n","train_summary_writer = tf.summary.create_file_writer('logs/train')\n","val_summary_writer = tf.summary.create_file_writer('logs/val')\n","\n","@tf.function\n","def train_step(model, images, labels, optimizer):\n","    with tf.GradientTape() as tape:\n","        loss = compute_loss(model, images, labels)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    return loss\n","\n","@tf.function\n","def val_step(model, images, labels):\n","    logits = model(images, training=False)\n","    loss = losses.cross_entropy(logits, labels, config)\n","    return loss\n","\n","for epoch in range(config.train_config.num_epochs):\n","    with train_summary_writer.as_default():\n","        for step, (images, labels) in enumerate(train_dataset):\n","            loss = train_step(model, images, labels, optimizer_fn(learning_rate_fn(epoch)))\n","            tf.summary.scalar('loss', loss, step=step)\n","    with val_summary_writer.as_default():\n","        for images, labels in val_dataset:\n","            loss = val_step(model, images, labels)\n","            tf.summary.scalar('val_loss', loss, step=epoch)"],"metadata":{"id":"RAX9AllBwiXM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# evaluation\n","from deeplab import metrics\n","\n","def evaluate(model, dataset):\n","    metric = metrics.MeanIoU(num_classes=config.num_classes)\n","    for images, labels in dataset:\n","        logits = model(images, training=False)\n","        predictions = tf.argmax(logits, axis=-1)\n","        metric.update_state(labels, predictions)\n","    miou = metric.result()\n","    return miou.numpy()\n","\n","latest_checkpoint = tf.train.latest_checkpoint('checkpoints')\n","model.load_weights(latest_checkpoint)\n","\n","val_dataset = input_preprocess.load('cityscapes/tfrecord/val', config, is_training=False)\n","\n","miou = evaluate(model, val_dataset)\n","print('Validation mIoU:', miou)\n"],"metadata":{"id":"AddF6YLKwmg-"},"execution_count":null,"outputs":[]}]}